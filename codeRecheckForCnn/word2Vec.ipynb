{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "f6959045-6fb8-4f98-801a-edf6b1265543",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import d2lzh as d2l\n",
    "import math\n",
    "from mxnet import autograd,gluon,nd\n",
    "from mxnet.gluon import data as gdata,loss as gloss,nn\n",
    "import random\n",
    "import sys\n",
    "import time\n",
    "import zipfile\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "id": "f3fbe9c4-679c-4fd2-ae7d-00940c061f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def skip_gram(center,context_and_negatives,embed_v,embed_u):\n",
    "    v=embed_v(center)\n",
    "    u=embed_u(context_and_negatives)\n",
    "    pred=nd.batch_dot(v,u.swapaxes(1,2))\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "id": "de2390ee-05a0-4fca-9b4b-4e6cb6ef2ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss=gloss.SigmoidBinaryCrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "id": "39cb42cf-75ce-473a-92e8-aa3da0bf420a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmd(x):\n",
    "    return -math.log(1/(1+math.exp(-x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "id": "8d7faba3-0868-4cd4-aecb-5182addd914d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file_data(filePath):\n",
    "    f=open(\"data/wordTrain/train_cnn.lex\")\n",
    "    lines=f.readlines()\n",
    "    raw_dataset=[st.split() for st in lines]\n",
    "    #for st in raw_dataset[:3]:\n",
    "     #   print('# tokens:',len(st),st[:5])    \n",
    "    counter=collections.Counter([tk for st in raw_dataset for tk in st])\n",
    "    counter=dict(filter(lambda x:x[1]>=5,counter.items()))\n",
    "    idx_to_token=[tk for tk,_ in counter.items()]\n",
    "    token_to_idx={tk:idx for idx, tk in enumerate(idx_to_token)}\n",
    "    dataset=[[token_to_idx[tk] for tk in st if tk in token_to_idx] for st in raw_dataset]\n",
    "    num_tokens=sum([len(st) for st in dataset])\n",
    "    return idx_to_token,token_to_idx,dataset,counter,num_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "id": "43f03123-68b1-4ecc-8baa-388eeab7c7f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "235634\n",
      "[[0, 1, 2], [3, 4], [5, 1, 6, 2, 7, 8], [5, 1, 6, 2, 7, 8], [5, 1, 8], [5, 1, 8], [5, 1, 8], [9, 8], [3, 4], [3, 4, 10, 8]]\n"
     ]
    }
   ],
   "source": [
    "idx_to_token,token_to_idx,dataset,counter,num_tokens=read_file_data(\"data/wordTrain/train_cnn.lex\")\n",
    "print(num_tokens)\n",
    "print(dataset[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "id": "987b5a80-16a2-463b-877c-3d0aaacce645",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discard(idx):\n",
    "    return random.uniform(0,1)<1-math.sqrt(1e-4/counter[idx_to_token[idx]]*num_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "id": "3320e5c8-4d2c-44e8-b7b1-d247685c232f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1], [], [], [], [], [5], [], [], [], []]\n",
      "[[1], [5], [3], [4], [10], [12, 16], [20], [21], [24], [22]]\n",
      "13759\n"
     ]
    }
   ],
   "source": [
    "subsampled_dataset=[[tk for tk in st if not discard(tk)] for st in dataset]\n",
    "subsampled_dataset2=[x for x in subsampled_dataset if x!=[]]\n",
    "print(subsampled_dataset[0:10])\n",
    "num_tokens=sum([len(st) for st in subsampled_dataset])\n",
    "print(subsampled_dataset2[0:10])\n",
    "print(num_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "id": "f2a15f2a-9b4b-4351-9589-7ac0d0ddefd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_centers_and_contexts(dataset,max_windows_size):\n",
    "    centers,contexts=[],[]\n",
    "    for st in dataset:\n",
    "        if len(st)<2:\n",
    "            continue\n",
    "        centers+=st\n",
    "        for center_i in range(len(st)):\n",
    "            windows_size=random.randint(1,max_windows_size)\n",
    "            indices=list(range(max(0,center_i-windows_size),min(len(st),center_i+1+windows_size)))\n",
    "            indices.remove(center_i)\n",
    "            contexts.append([st[idx] for idx in indices])\n",
    "    return centers,contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "id": "4bf0dfb4-59d7-4d22-9ba7-9046fda9c98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_centers,all_contexts=get_centers_and_contexts(subsampled_dataset,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "id": "70d5b5a4-5a4d-4542-bb0e-021e310ecbc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_negatives(all_contexts,sampling_weights,K):\n",
    "    all_negatives,neg_candidates,i=[],[],0\n",
    "    population=list(range(len(sampling_weights)))\n",
    "    for contexts in all_contexts:\n",
    "        negatives=[]\n",
    "        while len(negatives)<len(contexts)*K:\n",
    "            if i==len(neg_candidates):\n",
    "                i,neg_candidates=0,random.choices(population,sampling_weights,k=int(1e5))\n",
    "            neg,i=neg_candidates[i],i+1\n",
    "            if neg not in set(contexts):\n",
    "                negatives.append(neg)\n",
    "        all_negatives.append(negatives)\n",
    "    return all_negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "id": "bf93b2d6-29a0-4a15-8f69-de8acb6f4ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_weights=[counter[W]**0.75 for W in idx_to_token]\n",
    "all_negatives=get_negatives(all_contexts,sampling_weights,5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "id": "9e9228fc-1bd9-457c-b92d-4d05babd2492",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batchify(data):\n",
    "    max_len=max(len(c)+len(n) for _,c,n in data)\n",
    "    centers,contexts_negatives,masks,labels=[],[],[],[]\n",
    "    for center,context,negatives in data:\n",
    "        cur_len=len(context)+len(negatives)\n",
    "        centers+=[center]\n",
    "        contexts_negatives+=[context+negatives+[0]*(max_len-cur_len)]\n",
    "        masks+=[[1]*cur_len+[0]*(max_len-cur_len)]\n",
    "        labels+=[[1]*len(context)+[0]*(max_len-len(context))]\n",
    "    return (nd.array(centers).reshape((-1,1)),nd.array(contexts_negatives),nd.array(masks),nd.array(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "id": "7c71ec45-c238-4fba-8f34-48adea826ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=512\n",
    "num_workers=0 if sys.platform.startswith('win32') else 4\n",
    "dataset=gdata.ArrayDataset(all_centers,all_contexts,all_negatives)\n",
    "data_iter=gdata.DataLoader(dataset,batch_size,shuffle=True,batchify_fn=batchify,num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "id": "63c791c6-1cbc-4eff-9791-004c4cd9075d",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_size=20\n",
    "net=nn.Sequential()\n",
    "net.add(nn.Embedding(input_dim=len(idx_to_token),output_dim=embed_size),\n",
    "        nn.Embedding(input_dim=len(idx_to_token),output_dim=embed_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "id": "39454c10-aa3a-4978-87da-2d5f9e0ad08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net,lr,num_epochs):\n",
    "    ctx=d2l.try_gpu()\n",
    "    net.initialize(ctx=ctx,force_reinit=True)\n",
    "    trainer=gluon.Trainer(net.collect_params(),'adam',{'learning_rate':lr})\n",
    "    for epoch in range(num_epochs):\n",
    "        start,l_sum,n=time.time(),0.0,0\n",
    "        for batch in data_iter:\n",
    "            center,context_negative,mask,label=[data.as_in_context(ctx) for data in batch]\n",
    "            with autograd.record():\n",
    "                pred=skip_gram(center,context_negative,net[0],net[1])\n",
    "                l=(loss(pred.reshape(label.shape),label,mask)*mask.shape[1]/mask.sum(axis=1))\n",
    "            l.backward()\n",
    "            trainer.step(batch_size)\n",
    "            l_sum+=l.sum().asscalar()\n",
    "            n+=l.size\n",
    "        print('epoch %d, loss %.2f,time %.2fs'%(epoch+1,l_sum/n,time.time()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "id": "2dcea7ce-e8ae-4716-8290-35eb02fea7e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss 0.69,time 0.33s\n",
      "epoch 2, loss 0.66,time 0.29s\n",
      "epoch 3, loss 0.58,time 0.28s\n",
      "epoch 4, loss 0.49,time 0.28s\n",
      "epoch 5, loss 0.44,time 0.28s\n",
      "epoch 6, loss 0.44,time 0.29s\n",
      "epoch 7, loss 0.43,time 0.28s\n",
      "epoch 8, loss 0.43,time 0.27s\n",
      "epoch 9, loss 0.43,time 0.28s\n",
      "epoch 10, loss 0.43,time 0.28s\n",
      "epoch 11, loss 0.43,time 0.28s\n",
      "epoch 12, loss 0.43,time 0.28s\n",
      "epoch 13, loss 0.42,time 0.28s\n",
      "epoch 14, loss 0.42,time 0.28s\n",
      "epoch 15, loss 0.42,time 0.27s\n",
      "epoch 16, loss 0.42,time 0.27s\n",
      "epoch 17, loss 0.41,time 0.28s\n",
      "epoch 18, loss 0.41,time 0.29s\n",
      "epoch 19, loss 0.41,time 0.28s\n",
      "epoch 20, loss 0.40,time 0.27s\n",
      "epoch 21, loss 0.40,time 0.32s\n",
      "epoch 22, loss 0.40,time 0.28s\n",
      "epoch 23, loss 0.39,time 0.28s\n",
      "epoch 24, loss 0.39,time 0.27s\n",
      "epoch 25, loss 0.39,time 0.28s\n",
      "epoch 26, loss 0.39,time 0.28s\n",
      "epoch 27, loss 0.39,time 0.27s\n",
      "epoch 28, loss 0.38,time 0.28s\n",
      "epoch 29, loss 0.38,time 0.29s\n",
      "epoch 30, loss 0.38,time 0.28s\n",
      "epoch 31, loss 0.38,time 0.28s\n",
      "epoch 32, loss 0.38,time 0.27s\n",
      "epoch 33, loss 0.38,time 0.30s\n",
      "epoch 34, loss 0.38,time 0.27s\n",
      "epoch 35, loss 0.38,time 0.27s\n",
      "epoch 36, loss 0.37,time 0.30s\n",
      "epoch 37, loss 0.37,time 0.27s\n",
      "epoch 38, loss 0.37,time 0.28s\n",
      "epoch 39, loss 0.37,time 0.28s\n",
      "epoch 40, loss 0.37,time 0.27s\n",
      "epoch 41, loss 0.37,time 0.32s\n",
      "epoch 42, loss 0.37,time 0.28s\n",
      "epoch 43, loss 0.37,time 0.26s\n",
      "epoch 44, loss 0.37,time 0.28s\n",
      "epoch 45, loss 0.37,time 0.27s\n",
      "epoch 46, loss 0.37,time 0.28s\n",
      "epoch 47, loss 0.37,time 0.27s\n",
      "epoch 48, loss 0.37,time 0.29s\n",
      "epoch 49, loss 0.37,time 0.28s\n",
      "epoch 50, loss 0.37,time 0.28s\n",
      "epoch 51, loss 0.36,time 0.27s\n",
      "epoch 52, loss 0.36,time 0.29s\n",
      "epoch 53, loss 0.36,time 0.28s\n",
      "epoch 54, loss 0.36,time 0.27s\n",
      "epoch 55, loss 0.36,time 0.28s\n",
      "epoch 56, loss 0.36,time 0.28s\n",
      "epoch 57, loss 0.36,time 0.28s\n",
      "epoch 58, loss 0.36,time 0.27s\n",
      "epoch 59, loss 0.36,time 0.30s\n",
      "epoch 60, loss 0.36,time 0.28s\n",
      "epoch 61, loss 0.36,time 0.27s\n",
      "epoch 62, loss 0.36,time 0.32s\n",
      "epoch 63, loss 0.36,time 0.27s\n",
      "epoch 64, loss 0.36,time 0.29s\n",
      "epoch 65, loss 0.36,time 0.27s\n",
      "epoch 66, loss 0.36,time 0.28s\n",
      "epoch 67, loss 0.36,time 0.27s\n",
      "epoch 68, loss 0.36,time 0.30s\n",
      "epoch 69, loss 0.36,time 0.28s\n",
      "epoch 70, loss 0.36,time 0.28s\n",
      "epoch 71, loss 0.36,time 0.27s\n",
      "epoch 72, loss 0.36,time 0.29s\n",
      "epoch 73, loss 0.36,time 0.27s\n",
      "epoch 74, loss 0.36,time 0.28s\n",
      "epoch 75, loss 0.36,time 0.30s\n",
      "epoch 76, loss 0.36,time 0.28s\n",
      "epoch 77, loss 0.36,time 0.27s\n",
      "epoch 78, loss 0.36,time 0.28s\n",
      "epoch 79, loss 0.36,time 0.28s\n",
      "epoch 80, loss 0.36,time 0.29s\n",
      "epoch 81, loss 0.36,time 0.28s\n",
      "epoch 82, loss 0.36,time 0.27s\n",
      "epoch 83, loss 0.36,time 0.32s\n",
      "epoch 84, loss 0.36,time 0.28s\n",
      "epoch 85, loss 0.36,time 0.28s\n",
      "epoch 86, loss 0.36,time 0.27s\n",
      "epoch 87, loss 0.36,time 0.27s\n",
      "epoch 88, loss 0.36,time 0.30s\n",
      "epoch 89, loss 0.36,time 0.29s\n",
      "epoch 90, loss 0.36,time 0.27s\n",
      "epoch 91, loss 0.36,time 0.30s\n",
      "epoch 92, loss 0.36,time 0.27s\n",
      "epoch 93, loss 0.36,time 0.28s\n",
      "epoch 94, loss 0.36,time 0.28s\n",
      "epoch 95, loss 0.35,time 0.27s\n",
      "epoch 96, loss 0.35,time 0.28s\n",
      "epoch 97, loss 0.35,time 0.27s\n",
      "epoch 98, loss 0.35,time 0.28s\n",
      "epoch 99, loss 0.35,time 0.28s\n",
      "epoch 100, loss 0.35,time 0.28s\n"
     ]
    }
   ],
   "source": [
    "train(net,0.005,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "id": "53264754-7b3a-47cf-a2d1-dffa4a28671d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similar_tokens(query_token,k,embed):\n",
    "    W=embed.weight.data()\n",
    "    x=W[token_to_idx[query_token]]\n",
    "    cos=nd.dot(W,x)/(nd.sum(W*W,axis=1)*nd.sum(x*x)+1e-9).sqrt()\n",
    "    topk=nd.topk(cos,k=k+1,ret_typ='indices').asnumpy().astype('int32')\n",
    "    for i in topk[1:]:\n",
    "        print('cosine sim=%.3f:%s'%(cos[i].asscalar(),(idx_to_token[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "id": "3c5b65b9-9bee-4d1c-b13c-d1f91d3dac3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cosine sim=0.869:fwrite\n",
      "cosine sim=0.553:memset\n",
      "cosine sim=0.545:=\n",
      "cosine sim=0.541:stdin\n",
      "cosine sim=0.478:assert\n",
      "cosine sim=0.469:goto\n",
      "cosine sim=0.447:feof\n",
      "cosine sim=0.446:!\n",
      "cosine sim=0.440:&\n",
      "cosine sim=0.407:fflush\n",
      "cosine sim=0.403:strcmp\n",
      "cosine sim=0.399:struct_var\n",
      "cosine sim=0.398:NULL\n",
      "cosine sim=0.397:call_func\n",
      "cosine sim=0.390:/\n",
      "cosine sim=0.384:+\n",
      "cosine sim=0.380:malloc\n",
      "cosine sim=0.378:>=\n",
      "cosine sim=0.372:<=\n",
      "cosine sim=0.366:-\n"
     ]
    }
   ],
   "source": [
    "get_similar_tokens('fread',20,net[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91ed563-092a-4d0c-96d2-7927430ba879",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc48fd6-04aa-4b5a-9856-19043c0b6f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#net.save('data/params/word.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e083c46f-a1c0-4994-8d0c-496a49dc6d4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6c2b8e-e1b9-47f2-af06-1499faf5ac03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2dfd180-cb66-4f1b-a1af-24723c361b44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5974b6f5-ba21-4334-888b-2b63ecd7948b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "id": "6fd2b9a7-07f0-4044-abdc-06142c588d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_weight=net[0].weight.data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "4e916a89-d445-48c7-9ff7-56b32092d27c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "id": "fc62f894-269f-48ff-a05c-7b817f0f381f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_params(filePath,idx_to_token,embedding_weight):\n",
    "    temp_one=np.array(idx_to_token)\n",
    "    np.save(filePath+'idx_to_token.npy',temp_one)\n",
    "    #temp_two=np.array(token_to_idx)\n",
    "    #np.save(filePath+'token_to_idx.npy',temp_two)\n",
    "    nd.save(filePath+'embedding_weight.txt',embedding_weight)\n",
    "    return;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "658e8773-7877-4db0-a251-2cc359fa0728",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_params(filePath):\n",
    "    idx_to_token=np.load(filePath+'idx_to_token.npy')\n",
    "    #token_to_idx=np.load(filePath+'token_to_idx.npy')\n",
    "    token_to_idx={tk:idx for idx,tk in enumerate(idx_to_token)}\n",
    "    embedding_weight=nd.load(filePath+'embedding_weight.txt')\n",
    "    return idx_to_token,token_to_idx,embedding_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "id": "22813eec-cf42-4fb8-80a2-a349c20a0f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_params('data/params/word2Vec/',idx_to_token,embedding_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "3412cbc4-4b66-48b2-99c5-891cbd128a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_idx_to_token,temp_token_to_idx,temp_embedding_weight=read_params('data/params/word2Vec/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "68715f54-d3f1-4e54-91a6-15d945de0e08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['#define' 'var' 'nums' 'struct' 'struct_name' 'data_type' '[' ']' ';' '}'\n",
      " 'struct_var' '*' 'void' 'func' '(' ')' '{' 'printf' 'words' 'while'\n",
      " 'switch' 'case' ':' 'call_func' 'break' 'fflush' 'stdin' 'gets' '=' 'if'\n",
      " '<' '|' '>' 'else' 'return' 'FILE' 'fopen' ',' 'for' 'fread' '+' 'sizeof'\n",
      " '!' '.' 'fclose' 'NULL' '-' 'do' 'continue' 'strcmp' '&' 'scanf' 'malloc'\n",
      " 'fwrite' 'default' 'getch' 'feof' 'system' '<=' 'typedef' '>=' 'free' '/'\n",
      " 'memset' 'static' 'goto' 'extern' '#endif' '#ifndef' 'assert' '#else']\n",
      "['#define', 'var', 'nums', 'struct', 'struct_name', 'data_type', '[', ']', ';', '}', 'struct_var', '*', 'void', 'func', '(', ')', '{', 'printf', 'words', 'while', 'switch', 'case', ':', 'call_func', 'break', 'fflush', 'stdin', 'gets', '=', 'if', '<', '|', '>', 'else', 'return', 'FILE', 'fopen', ',', 'for', 'fread', '+', 'sizeof', '!', '.', 'fclose', 'NULL', '-', 'do', 'continue', 'strcmp', '&', 'scanf', 'malloc', 'fwrite', 'default', 'getch', 'feof', 'system', '<=', 'typedef', '>=', 'free', '/', 'memset', 'static', 'goto', 'extern', '#endif', '#ifndef', 'assert', '#else']\n"
     ]
    }
   ],
   "source": [
    "print(temp_idx_to_token)\n",
    "print(idx_to_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "d329e438-c13b-4ae7-b4aa-da2c7e74a143",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'#define': 0, 'var': 1, 'nums': 2, 'struct': 3, 'struct_name': 4, 'data_type': 5, '[': 6, ']': 7, ';': 8, '}': 9, 'struct_var': 10, '*': 11, 'void': 12, 'func': 13, '(': 14, ')': 15, '{': 16, 'printf': 17, 'words': 18, 'while': 19, 'switch': 20, 'case': 21, ':': 22, 'call_func': 23, 'break': 24, 'fflush': 25, 'stdin': 26, 'gets': 27, '=': 28, 'if': 29, '<': 30, '|': 31, '>': 32, 'else': 33, 'return': 34, 'FILE': 35, 'fopen': 36, ',': 37, 'for': 38, 'fread': 39, '+': 40, 'sizeof': 41, '!': 42, '.': 43, 'fclose': 44, 'NULL': 45, '-': 46, 'do': 47, 'continue': 48, 'strcmp': 49, '&': 50, 'scanf': 51, 'malloc': 52, 'fwrite': 53, 'default': 54, 'getch': 55, 'feof': 56, 'system': 57, '<=': 58, 'typedef': 59, '>=': 60, 'free': 61, '/': 62, 'memset': 63, 'static': 64, 'goto': 65, 'extern': 66, '#endif': 67, '#ifndef': 68, 'assert': 69, '#else': 70}\n"
     ]
    }
   ],
   "source": [
    "#temp_token_to_idx={tk:idx for idx,tk in enumerate(temp_idx_to_token)}\n",
    "print(temp_token_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "b609d08b-6b46-45d9-b5f6-3fbbe4981a77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'#define': 0, 'var': 1, 'nums': 2, 'struct': 3, 'struct_name': 4, 'data_type': 5, '[': 6, ']': 7, ';': 8, '}': 9, 'struct_var': 10, '*': 11, 'void': 12, 'func': 13, '(': 14, ')': 15, '{': 16, 'printf': 17, 'words': 18, 'while': 19, 'switch': 20, 'case': 21, ':': 22, 'call_func': 23, 'break': 24, 'fflush': 25, 'stdin': 26, 'gets': 27, '=': 28, 'if': 29, '<': 30, '|': 31, '>': 32, 'else': 33, 'return': 34, 'FILE': 35, 'fopen': 36, ',': 37, 'for': 38, 'fread': 39, '+': 40, 'sizeof': 41, '!': 42, '.': 43, 'fclose': 44, 'NULL': 45, '-': 46, 'do': 47, 'continue': 48, 'strcmp': 49, '&': 50, 'scanf': 51, 'malloc': 52, 'fwrite': 53, 'default': 54, 'getch': 55, 'feof': 56, 'system': 57, '<=': 58, 'typedef': 59, '>=': 60, 'free': 61, '/': 62, 'memset': 63, 'static': 64, 'goto': 65, 'extern': 66, '#endif': 67, '#ifndef': 68, 'assert': 69, '#else': 70, '#undef': 71, 'union': 72}\n"
     ]
    }
   ],
   "source": [
    "print(token_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6036d94c-93de-4ceb-ad61-29457d06e8f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
